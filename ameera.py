# -*- coding: utf-8 -*-
"""Ameera.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vbhw2tNv1hzCJAGhzp1GBOdd7O1p4ulg

Confirmed by omar
"""

!nvidia-smi

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from sklearn.metrics import accuracy_score, confusion_matrix
import cudf
import cuml
from cuml.linear_model import LogisticRegression
from cuml.model_selection import train_test_split
from cuml.preprocessing import StandardScaler
from cuml.model_selection import GridSearchCV

!pip install kaggle

from google.colab import files
files.upload()  # Upload your kaggle.json file

!wget https://www.kaggle.com/api/v1/datasets/download/mountboy/online-store-customer-transactions-1m-rows

import os
print(os.listdir('/content'))

!file /content/online-store-customer-transactions-1m-rows

!unzip /content/online-store-customer-transactions-1m-rows -d /content/extracted_data

df = cudf.read_csv('/content/extracted_data/customer_spending_1M_2018_2025.csv')

df.info()
df.head(10)

sampled_df = df.sample(n=200, random_state=42) # Setting random_state for reproducibility

sampled_df.to_csv('test.csv', index=False)

print("Loading the dataset...")
N_SAMPLES = 1000000
column_names = ['label'] + [f'feature_{i}' for i in range(1, 29)]

df.shape

df.isnull().sum()

df = df.dropna()
df.isnull().sum()

print(df.dtypes)

df.describe()

df.duplicated().sum()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

numerical_cols = df.select_dtypes(include=['number'])
correlation_matrix = numerical_cols.corr().to_pandas()

plt.figure(figsize=(20, 16))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f",
            square=True, linewidths=0.5, cbar_kws={'shrink': 0.6})
plt.title('Correlation Matrix Heatmap', fontsize=18)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

df.shape

print("\nDataset shape:", df.shape)
print("\nSample of the data:")
print(df.head())
print("\nClass distribution:")
print(df['Amount_spent'].value_counts())

df_pandas = df.to_pandas()

plt.figure(figsize=(10, 6))
plt.hist(df_pandas['Amount_spent'], bins=50, color='skyblue', edgecolor='black')
plt.title('Distribution of spending amount')
plt.xlabel('Amount Spent')
plt.ylabel('Frequency')
plt.show()

df_pandas = df.to_pandas()

plt.figure(figsize=(10, 6))
plt.scatter(df_pandas['Age'], df_pandas['Amount_spent'], alpha=0.5)
plt.title('The relationship between age and spending amount')
plt.xlabel('Age')
plt.ylabel('Amount Spent')
plt.show()

df_pandas = df.to_pandas()

gender_counts = df_pandas['Gender'].value_counts()

gender_counts_values = gender_counts.values

plt.figure(figsize=(8, 6))
plt.bar(gender_counts.index, gender_counts_values, color='skyblue', edgecolor='black')
plt.title('Gender distribution')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

import cudf
from cuml.model_selection import train_test_split
from cuml.preprocessing import LabelEncoder




df = df.dropna()

target = df["Amount_spent"]
features = df.drop(columns=["Amount_spent"], axis=1)

for col in features.columns:
    if features[col].dtype == 'object':
        le = LabelEncoder()
        features[col] = le.fit_transform(features[col])

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

print(X_train.head())

features

target

features= cudf.DataFrame.from_pandas(features)
target = cudf.Series.from_pandas(target)

start_time = time.time()
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
preprocess_time = time.time() - start_time
print(f"GPU preprocessing time: {preprocess_time:.2f} seconds")

print("\nTraining logistic regression with cuML (GPU)...")
start_time = time.time()
# Use cuml.linear_model.LogisticRegression explicitly
lr_model = cuml.linear_model.LogisticRegression(max_iter=1000, solver='qn')
lr_model.fit(X_train_scaled, y_train)
train_time = time.time() - start_time
print(f"GPU training time: {train_time:.2f} seconds")

import cuml
import cudf
from cuml.linear_model import LinearRegression as cuLR
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

X_train_cudf = cudf.DataFrame.from_pandas(X_train)
y_train_cudf = cudf.Series(y_train.values)
X_test_cudf = cudf.DataFrame.from_pandas(X_test)
y_test_cudf = cudf.Series(y_test.values)

model = cuLR()

model.fit(X_train_cudf, y_train_cudf)

y_pred_cudf = model.predict(X_test_cudf)

y_pred = y_pred_cudf.to_numpy()

y_test_np = y_test_cudf.to_numpy()

mae = mean_absolute_error(y_test_np, y_pred)
mse = mean_squared_error(y_test_np, y_pred)
r2 = r2_score(y_test_np, y_pred)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R² Score: {r2}")

import numpy as np
import cudf
from cuml.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
import time

# Log-transform target values
y_train_log = np.log1p(y_train.to_numpy())
y_test_log = np.log1p(y_test.to_numpy())

# Convert to cuDF DataFrames
X_train_cudf = cudf.DataFrame.from_pandas(X_train_scaled)
X_test_cudf = cudf.DataFrame.from_pandas(X_test_scaled)
y_train_cudf = cudf.Series(y_train_log)
y_test_np = y_test.to_numpy()

# Adjusted parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20],
    'max_features': [0.7, 0.8, 1.0],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [2, 5],
    'bootstrap': [True, False]
}

best_r2 = -np.inf
best_params = None
best_model = None
best_y_pred_log = None

# Grid search with Cross-validation
for n in param_grid['n_estimators']:
    for d in param_grid['max_depth']:
        for f in param_grid['max_features']:
            print(f"\n Testing: n_estimators={n}, max_depth={d}, max_features={f}")

            model = RandomForestRegressor(n_estimators=n, max_depth=d, max_features=f, random_state=42)

            start_train = time.time()
            model.fit(X_train_cudf, y_train_cudf)
            end_train = time.time()

            start_pred = time.time()
            y_pred_log = model.predict(X_test_cudf).to_numpy()
            end_pred = time.time()

            y_pred = np.expm1(y_pred_log)

            mae_R = mean_absolute_error(y_test_np, y_pred)
            mse_R = mean_squared_error(y_test_np, y_pred)
            r2_R = r2_score(y_test_np, y_pred)

            print(f" Training Time: {end_train - start_train:.2f}s | Prediction Time: {end_pred - start_pred:.2f}s")
            print(f" MAE: {mae:.2f} | MSE: {mse:.2f} | R²: {r2:.4f}")
            print("--------------------------------------------------")

            if r2 > best_r2:
                best_r2 = r2
                best_params = {'n_estimators': n, 'max_depth': d, 'max_features': f}
                best_model = model
                best_y_pred_log = y_pred_log

# Output the best parameters
print(f"\n Best R²: {best_r2:.4f} with params: {best_params}")

# Final evaluation with the best model
best_y_pred = np.expm1(best_y_pred_log)
mae_final = mean_absolute_error(y_test_np, best_y_pred)
mse_final = mean_squared_error(y_test_np, best_y_pred)
r2_final = r2_score(y_test_np, best_y_pred)

print(f"\n Final Results with Best Model:")
print(f"MAE: {mae_final:.2f}")
print(f"MSE: {mse_final:.2f}")
print(f"R² Score: {r2_final:.4f}")

import matplotlib.pyplot as plt

models = ['Random Forest', 'Linear Regression']
mae_values = [mae_final, mae]
mse_values = [mse_final, mse]
r2_values = [r2_final, r2]

plt.figure(figsize=(12, 6))
plt.subplot(1, 3, 1)
plt.bar(models, mae_values, color='lightblue')
plt.title('Mean Absolute Error (MAE)')
plt.xlabel('Models')
plt.ylabel('MAE')

plt.subplot(1, 3, 2)
plt.bar(models, mse_values, color='lightgreen')
plt.title('Mean Squared Error (MSE)')
plt.xlabel('Models')
plt.ylabel('MSE')

plt.subplot(1, 3, 3)
plt.bar(models, r2_values, color='lightcoral')
plt.title('R² Score')
plt.xlabel('Models')
plt.ylabel('R²')

plt.tight_layout()
plt.show()

import joblib

# Save the trained model
joblib.dump(lr_model, 'lr_model.joblib')

# Save the scaler
joblib.dump(scaler, 'scaler.joblib')

import joblib

# Load the saved model
loaded_model = joblib.load('lr_model.joblib')

# Print all attributes of the loaded model
for attr in dir(loaded_model):
    if not attr.startswith("__"):  # Exclude special attributes
        print(attr) # Indented this line to be inside the 'if' block

import joblib

# Load the model
loaded_model = joblib.load('lr_model.joblib')

# Access model coefficients
coefficients = loaded_model.coef_
print("Coefficients:\n", coefficients)

# Access model intercept
intercept = loaded_model.intercept_
print("Intercept:\n", intercept)

import joblib

# Load the trained model
loaded_model = joblib.load('lr_model.joblib')

# Load the scaler
loaded_scaler = joblib.load('scaler.joblib')

# Now you can use loaded_model and loaded_scaler to make predictions
# ... (rest of your prediction code)

X_test.to_csv('X_test.csv', index=False)
y_test.to_pandas().to_csv('y_test.csv', index=False) # Convert y_test to pandas Series before calling to_csv

import pandas as pd
import joblib
from cuml.preprocessing import StandardScaler

# Load the saved model and scaler
loaded_model = joblib.load('lr_model.joblib')
loaded_scaler = joblib.load('scaler.joblib')

# Load the test data
X_test = pd.read_csv('X_test.csv')
y_test = pd.read_csv('y_test.csv')

# Convert pandas DataFrames to cuDF DataFrames
import cudf
X_test_cudf = cudf.DataFrame.from_pandas(X_test)

# Scale the test data using the loaded scaler
X_test_scaled = loaded_scaler.transform(X_test_cudf)

# Make predictions using the loaded model
y_pred = loaded_model.predict(X_test_scaled)

# Evaluate the model (optional)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred.to_pandas()) # Convert to pandas for sklearn
print(f"Model Accuracy: {accuracy:.4f}")

import os

# تحديد المسار إلى الملف
file_path = 'X_test.csv'

# التحقق مما إذا كان الملف موجودًا
if os.path.exists(file_path):
    print(f"The file {file_path} exists.")
else:
    print(f"The file {file_path} does not exist.")

